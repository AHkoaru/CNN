{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch version: 2.4.0  Device: cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print('Using PyTorch version:', torch.__version__, ' Device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "\n",
    "train_data = datasets.MNIST('data', train=True, download=True, transform=transforms.ToTensor())\n",
    "test_data = datasets.MNIST('data', train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: torch.Size([20, 1, 28, 28]) type: torch.FloatTensor\n",
      "y_train: torch.Size([20]) type: torch.LongTensor\n"
     ]
    }
   ],
   "source": [
    "for (X_train, y_train) in train_loader:\n",
    "    print('X_train:', X_train.size(), 'type:', X_train.type())\n",
    "    print('y_train:', y_train.size(), 'type:', y_train.type())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 6\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "n = 1\n",
    "# Get the first image from X_train\n",
    "image = X_train[n]\n",
    "label = y_train[n]\n",
    "print('Label:', label.item())\n",
    "\n",
    "# Reshape the image tensor to 2D\n",
    "image = image.squeeze().cpu().numpy()\n",
    "\n",
    "# Display the image\n",
    "plt.imshow(image, cmap='gray', interpolation='nearest', aspect='equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3765, 0.5608,\n",
      "          1.0000, 0.9961, 0.7333, 0.2745, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.6039, 0.9176, 0.9804, 0.9922,\n",
      "          0.9922, 0.9922, 0.9922, 0.9608, 0.6157, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.2078, 0.8353, 0.9882, 0.9922, 0.9922, 0.9922,\n",
      "          0.9922, 0.9922, 0.9922, 0.9922, 0.9412, 0.3412, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.5137, 0.8980, 0.9922, 0.9922, 0.9922, 0.9922, 0.7294,\n",
      "          0.2392, 0.2392, 0.5020, 0.9804, 0.9922, 0.9333, 0.2235, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.6745, 0.9922, 0.9922, 0.9922, 0.9451, 0.4196, 0.0863,\n",
      "          0.0000, 0.0000, 0.0000, 0.5765, 0.9922, 0.9922, 0.2941, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.1294, 0.8627, 0.9922, 0.9922, 0.9686, 0.3176, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.4078, 0.9922, 0.9922, 0.2941, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.2196, 0.9922, 0.9922, 0.9922, 0.5608, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.4078, 0.9922, 0.9922, 0.2941, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.2196, 0.9922, 0.9922, 0.9922, 0.0353, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.4078, 0.9922, 0.9922, 0.2941, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.2196, 0.9922, 0.9922, 0.5333, 0.0039, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.5961, 0.9922, 0.9922, 0.2941, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.2196, 0.9922, 0.9922, 0.6196, 0.0078, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.9451, 0.9922, 0.9255, 0.2157, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.3216, 0.9922, 0.9922, 0.9922, 0.7333, 0.1804, 0.0000, 0.0000,\n",
      "          0.0000, 0.1255, 0.7294, 0.9804, 0.9922, 0.3569, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0353,\n",
      "          0.7804, 0.9922, 0.9294, 0.8863, 0.9333, 0.7725, 0.5961, 0.2471,\n",
      "          0.5490, 0.6118, 0.9922, 0.9922, 0.7804, 0.0745, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2980,\n",
      "          0.9922, 0.9922, 0.4039, 0.0000, 0.1882, 0.0471, 0.2353, 0.0078,\n",
      "          0.6549, 0.9922, 0.9922, 0.9922, 0.6549, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2980,\n",
      "          0.9922, 0.9255, 0.2078, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922,\n",
      "          0.9922, 0.9922, 0.9922, 0.7961, 0.0667, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2980,\n",
      "          0.9922, 0.8588, 0.0000, 0.0000, 0.0000, 0.0000, 0.4784, 0.9529,\n",
      "          0.9922, 0.9922, 0.9922, 0.0784, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0392,\n",
      "          0.7843, 0.9765, 0.3490, 0.0000, 0.1412, 0.5137, 0.9686, 0.9922,\n",
      "          0.9922, 0.8078, 0.4078, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.7529, 0.9922, 0.8353, 0.5216, 0.8745, 0.9922, 0.9922, 0.9922,\n",
      "          0.9647, 0.3255, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.3765, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.8588,\n",
      "          0.2627, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0824, 0.7922, 0.9922, 0.9922, 0.9922, 0.9922, 0.7804, 0.3059,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.3098, 0.7765, 0.9922, 0.7569, 0.4549, 0.0863, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000]]])\n"
     ]
    }
   ],
   "source": [
    "print('X_train:', X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_Kaiming(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.kaiming_normal_(m.weight.data)\n",
    "        m.bias.data.fill_(0.01)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
       "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_const = CNN().to(device)\n",
    "network_const.apply(init_Kaiming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_epoch(model, train_loader, optimizer, loss_func, epoch):\n",
    "    train_losses = []\n",
    "    train_correct = 0\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(data)\n",
    "\n",
    "        loss = loss_func(output, target)\n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "        predicted = torch.max(output.data, 1)[1]\n",
    "        train_correct += (predicted == target).sum()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % 1000 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            \n",
    "    return train_losses, train_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_epoch(model, test_loader, loss_func):\n",
    "    correct = 0\n",
    "    test_losses = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "\n",
    "            loss = loss_func(output, target)\n",
    "            test_losses.append(loss.item())\n",
    "\n",
    "            predicted = torch.max(output.data, 1)[1]\n",
    "            correct += (predicted == target).sum()\n",
    "\n",
    "        test_accuracy = 100. * correct / len(test_loader.dataset)\n",
    "\n",
    "        print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'\n",
    "              .format(correct, len(test_loader.dataset), test_accuracy))\n",
    "\n",
    "    return test_losses, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(network):\n",
    "\n",
    "    learning_rate = 0.01\n",
    "    epoches = 5\n",
    "\n",
    "    optimizer = optim.Adam(network.parameters(), lr=learning_rate)\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "    train_losses_per_epoch = []\n",
    "    test_losses_per_epoch = []\n",
    "    \n",
    "    train_accuracies = []\n",
    "    test_accuracies = []\n",
    "   \n",
    "    for epoch in range(epoches):\n",
    "\n",
    "        network.train()\n",
    "\n",
    "        train_losses, train_correct = training_epoch(network, train_loader, optimizer, loss_func, epoch)\n",
    "        train_losses_per_epoch.append(train_losses)\n",
    "\n",
    "        train_accuracy = 100. * train_correct / len(train_loader.dataset)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "\n",
    "        print('Epoch: {} - Train set: Accuracy: {}/{} ({:.0f}%)'\n",
    "              .format(epoch, train_correct, len(train_loader.dataset), train_accuracy))\n",
    "\n",
    "        network.eval()\n",
    "        with torch.no_grad():\n",
    "            test_losses, test_accuracy = test_epoch(network, test_loader, loss_func)\n",
    "\n",
    "        test_losses_per_epoch.append(test_losses)\n",
    "        test_accuracies.append(test_accuracy)\n",
    "\n",
    "    return train_losses_per_epoch, test_losses_per_epoch, train_accuracies, test_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.341518\n",
      "Train Epoch: 0 [20000/60000 (33%)]\tLoss: 0.039144\n",
      "Train Epoch: 0 [40000/60000 (67%)]\tLoss: 0.126570\n",
      "Epoch: 0 - Train set: Accuracy: 56714/60000 (95%)\n",
      "\n",
      "Test set: Accuracy: 9667/10000 (97%)\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.145347\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 0.012327\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 0.084086\n",
      "Epoch: 1 - Train set: Accuracy: 57980/60000 (97%)\n",
      "\n",
      "Test set: Accuracy: 9635/10000 (96%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.026676\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 0.123325\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 0.007516\n",
      "Epoch: 2 - Train set: Accuracy: 58217/60000 (97%)\n",
      "\n",
      "Test set: Accuracy: 9650/10000 (96%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.019826\n",
      "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 0.000080\n",
      "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 1.331633\n",
      "Epoch: 3 - Train set: Accuracy: 58277/60000 (97%)\n",
      "\n",
      "Test set: Accuracy: 9764/10000 (98%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.004142\n",
      "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 0.027814\n",
      "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 0.012541\n",
      "Epoch: 4 - Train set: Accuracy: 58453/60000 (97%)\n",
      "\n",
      "Test set: Accuracy: 9783/10000 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rlt_const = training(network_const)\n",
    "torch.save(network_const.state_dict(), 'mnist_cnn_const.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(network):\n",
    "    network.eval()\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    with torch.no_grad():\n",
    "        test_losses, test_accuracy = test_epoch(network, test_loader, loss_func)\n",
    "\n",
    "    return test_losses, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eodbs\\AppData\\Local\\Temp\\ipykernel_20256\\4209155824.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  network_const.load_state_dict(torch.load('mnist_cnn_const.pt'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Accuracy: 9783/10000 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "network_const.load_state_dict(torch.load('mnist_cnn_const.pt'))\n",
    "const_test = testing(network_const)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
